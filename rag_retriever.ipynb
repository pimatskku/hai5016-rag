{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94948360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_postgres import PGVector\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.tools import tool\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdfe6698",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  print(\"Please set the GOOGLE_API_KEY environment variable.\")\n",
    "\n",
    "model = init_chat_model(\"google_genai:gemini-2.5-flash\")\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f8fd36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"SUPABASE_CONNECTION_STRING\"):\n",
    "    print(\"Please set the SUPABASE_CONNECTION_STRING environment variable.\")\n",
    "\n",
    "vector_store = PGVector(\n",
    "    embeddings=embeddings,\n",
    "    collection_name=\"lilianweng_blog\",\n",
    "    connection=os.environ[\"SUPABASE_CONNECTION_STRING\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e857a359",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve_context(query: str):\n",
    "    \"\"\"Retrieve information to help answer a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=4)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcd95872",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "\n",
    "tools = [retrieve_context]\n",
    "# If desired, specify custom instructions\n",
    "prompt = (\n",
    "    \"You have access to a tool that retrieves context from a blog post. \"\n",
    "    \"Use the tool to help answer user queries.\"\n",
    ")\n",
    "agent = create_agent(model, tools, system_prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e3bbadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Wat zijn de uitdagingen en limieten bij het bouwen van een LLM agent?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_context (c51ee18b-6404-4c13-8f87-37b60dbe89cc)\n",
      " Call ID: c51ee18b-6404-4c13-8f87-37b60dbe89cc\n",
      "  Args:\n",
      "    query: uitdagingen en limieten LLM agent\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_context\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 39137}\n",
      "Content: Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\n",
      "\n",
      "\n",
      "Challenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 39948}\n",
      "Content: Reliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\n",
      "\n",
      "\n",
      "Citation#\n",
      "Cited as:\n",
      "\n",
      "Weng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 39002}\n",
      "Content: }\n",
      "]\n",
      "Challenges#\n",
      "After going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 8}\n",
      "Content: LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\n",
      "\n",
      "Planning\n",
      "\n",
      "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
      "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
      "\n",
      "\n",
      "Memory\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'text', 'text': 'Bij het bouwen van een LLM-agent zijn er verschillende uitdagingen en beperkingen:\\n\\n1.  **Beperkte contextlengte:** De eindige contextlengte beperkt de hoeveelheid historische informatie, gedetailleerde instructies, API-aanroepcontext en antwoorden die kunnen worden opgenomen. Dit bemoeilijkt het vermogen van de agent om te leren van fouten uit het verleden door middel van zelfreflectie.\\n2.  **Uitdagingen bij lange-termijnplanning en taakdecompositie:** LLM\\'s hebben moeite met plannen over een lange geschiedenis en het effectief verkennen van de oplossingsruimte. Ze vinden het ook moeilijk om plannen aan te passen wanneer er onverwachte fouten optreden, waardoor ze minder robuust zijn dan mensen.\\n3.  **Betrouwbaarheid van de natuurlijke taalinterface:** LLM\\'s kunnen opmaakfouten maken of \"rebels gedrag\" vertonen (bijvoorbeeld weigeren instructies op te volgen), wat de betrouwbaarheid van hun uitvoer beïnvloedt bij interactie met externe componenten zoals geheugen en tools. Dit vereist vaak veel moeite bij het parsen van de modeluitvoer.', 'extras': {'signature': 'CpUIAXLI2nzJxkpohh/pl2O+hxnH/LtBA6hkY03oRZjX5n8Ix+7jVHBvGbLWdrsRh9HJpvlFBKHRTqS0RLUW5FKVOnOv5acxlShta2Epf05PCgkIG0N1/MnTQeb7uzdZDcxiIbn2q7C+agldtI82hLfCNoOplcEzqVY3tCf+qKd9blXbS0RuU3lxVC2dyjIS0HwmITVKyCLLJyPvr0t/Z8ZGF450pulZzS4wKJ7WFneVVBxru178np7eJNgf7eBC29z2RH+wi8oCFMRAi77SNaehDCKbtafo1np/cTHGVH3w4QoeUL54EliZpree0H+qp2VajtLioj7cCcseqkcD+BH/wzklqldSktd5mRnJgd9Od1AIjmqirizDmthJ0TjkyDiGbUSY7XG2NSePuWXr5kzS01vTdWNI+tFQe9iIOb/UGKu5RCiPFUsEmmPg12vD6rb56KPCoHYN8tytUGG+MDyVR+OaGXRnCgYoCF/W4KVVPZZ5/yvepBlyFMddeXYro5go35GlXeHIm9uXZCwnTKcjUQT++KXptKyMurZ8QvduxxdSWtm/s4HmWP56bUCMI0HHMrztxy2eTMeo26pdih8i5zm2Gc/GMVlS+AW4ISXRm2MDI7uraCF1OtfAtfQgX6ICCy9dk9sG9PKFib8YmknWVeAlLEoXozgxZUofUIz76B7WgZ2JV9HBYXdIWb0NB7AGrhunHOqcHhqLa6duT4cEtJjG7PcuWOAeM9aE1DH1vhoTIpwgvpK7YX9SJqrXF4tc/jQSGiGgF+JFZ60UfHgvr7Y7LA1wRIDTTIsnFEKIoctEUYlcAFkr6DxfffzQ2+rKCDgUsI7hoSnJkOMht5MPCQiAHOEhR4cXh2G0mYxSIJDNRWOinNaA08y25r5PTCl7bh6aFPUKuZiDDA0ov+xAT3y9nYao8oR5uFBQ/go/QHQ0VSoy64zqp/gv22ZjYlECLfuKxAAUqO/9jHoaEjDOrbNYPzNJQrBy3Hv1LuDVK+gYi905no9oOflPjWKMQQ4whoY+D0epNgtfSai3RUAEnbY2CiOQ65/bgsax8uiyPn5jE+/XbmwXJqMo3SWYAgMY6o8+vx49IZHuP9+0Xh0GwWmDNrZFTii4KP3PuSFf3eyzd/ql8Z/PjMijc861O+/yOSWuuNzJgSfN8vC/Wga3sq52brIhqEtMy2LxozZDEm06UIS8QnEj5dqugjIVWddVl5ST2Soffi5dqrOY4SzNa6eBV7yxHEU4CaojT6GFn/aRDeKO7fAs3CoL7FzRzGab/cRl6mrTVuIDiCzo8TNC/nSZlubjbcDhxLed1696GpGga3BjLyWJz5+DFq0SZp3KJCN+Tpl0MtDe1M2KNHHlwWIz6UbOIMJ5sWNa1FagWuwBlQbJ+A=='}}]\n"
     ]
    }
   ],
   "source": [
    "query = (\n",
    "    \"Wat zijn de uitdagingen en limieten bij het bouwen van een LLM agent?\"\n",
    ")\n",
    "\n",
    "for event in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    last_message = event[\"messages\"][-1]\n",
    "    last_message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b063dc7e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf9e8fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Bij het bouwen van een LLM-agent zijn er verschillende uitdagingen en beperkingen:\n",
       "\n",
       "1.  **Beperkte contextlengte:** De eindige contextlengte beperkt de hoeveelheid historische informatie, gedetailleerde instructies, API-aanroepcontext en antwoorden die kunnen worden opgenomen. Dit bemoeilijkt het vermogen van de agent om te leren van fouten uit het verleden door middel van zelfreflectie.\n",
       "2.  **Uitdagingen bij lange-termijnplanning en taakdecompositie:** LLM's hebben moeite met plannen over een lange geschiedenis en het effectief verkennen van de oplossingsruimte. Ze vinden het ook moeilijk om plannen aan te passen wanneer er onverwachte fouten optreden, waardoor ze minder robuust zijn dan mensen.\n",
       "3.  **Betrouwbaarheid van de natuurlijke taalinterface:** LLM's kunnen opmaakfouten maken of \"rebels gedrag\" vertonen (bijvoorbeeld weigeren instructies op te volgen), wat de betrouwbaarheid van hun uitvoer beïnvloedt bij interactie met externe componenten zoals geheugen en tools. Dit vereist vaak veel moeite bij het parsen van de modeluitvoer."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Render the agent's last message as Markdown in the Jupyter output\n",
    "from IPython.display import Markdown, display\n",
    "display(Markdown(last_message.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f195906b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hai5016-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
